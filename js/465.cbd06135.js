"use strict";(self["webpackChunkoncapintada"]=self["webpackChunkoncapintada"]||[]).push([[465],{1465:function(a,e,t){t.r(e),t.d(e,{default:function(){return O}});var s=t(3396);const o={class:"view container container-fluid"},i=(0,s.uE)('<h1 class="mt-5 mb-3 title">Análise Modelos</h1><p class="mb-4"> Agora que já sabemos a forma da nossa base de dados, vamos analisá-la a partir do treinamento de modelos de machine learning. Aqui focaremos em modelos de aprendizado supervisionado, já que possuímos as anotações de cada objeto. </p><p class="mb-4"> Foi decidido que essa análise seria feita com 4 partições de treino diferentes: </p><ul><li>Dataset original (sem oversampling e undersampling)</li><li>Com undersampling, utilizando o algoritmo RandomUnderSampler</li><li>Com oversampling, utilizando o algoritmo SMOTE</li><li>Com oversampling, utilizando o algoritmo RandomOverSampler</li></ul><p class="mb-4"> OBS: Nas partições de validação e teste não foram utilizadas esses algoritmos. Além disso, as partições mantiveram as proporções de casos de fraude/não fraude do dataset original. </p><p class="mb-4"> Os modelos utilizados foram: Árvore de decisão, MLP, XBoosting, SHAP, Random Forest e o KNeighbors. Em todos os casos nós fizemos o cross-validation para assegurar que as métricas estavam corretas. </p><p class="mb-4"> A primeira coisa a ser observada é que o undersampling não é uma maneira eficiente de pre-processar os dados desbalanceados para treinamento. Em todos os modelos ele foi o que pior performou, classificando erroneamente muitos casos de não fraude como fraude. </p><p class="mb-4"> Matrix de confusão para o modelo de Decision Tree utilizando undersampling: </p><div class="tablePar"><table class="table tableMat table-bordered mb-4 mb-3"><caption> Predição do modelo </caption><thead class="table-success"><tr><th></th><th>0</th><th>1</th></tr></thead><tbody><tr><th class="table-secondary">0</th><td>40211</td><td>5294</td></tr><tr><th class="table-secondary">1</th><td>5</td><td>59</td></tr></tbody></table></div><p class="mb-4"> Indo na contramão desse caso, as partições sem undersampling e oversampling(dataset original) e as com oversampling (RandomOverSampler) obtiveram os melhores resultados. Já as partições com oversampling (SMOTE) ficaram no meio do caminho, sendo melhores que as com undersampling mas piores que as outras duas partições. </p><p class="mb-4"> O modelo que obteve a melhor performance foi o Random Forest e se aproximou de resultados obtidos na <a class="text-reset link-success link-underline-opacity-25 link-underline-opacity-100-hover" href="https://ieeexplore.ieee.org/document/8717766" target="_blank">literatura científica</a>. Ele não errou nenhum dos casos que classificou como fraude (da partição de validação) e obteve as melhores métricas de validação. Para a partição de teste, ele atingiu os seguintes resultados: </p><div class="tablePar"><table class="table tableMat table-bordered mb-4 mb-3"><caption> Predição do modelo </caption><thead class="table-success"><tr><th></th><th>0</th><th>1</th></tr></thead><tbody><tr><th class="table-secondary">0</th><td>56862</td><td>2</td></tr><tr><th class="table-secondary">1</th><td>22</td><td>76</td></tr></tbody></table></div><div class="tablePar"><table class="table table-bordered mb-4 mb-3"><caption> Métricas de avaliação do modelo </caption><thead class="table-success"><tr><th></th><th>Precision</th><th>Recall</th><th>F1</th><th>Specificity</th><th>Geom. Mean</th><th>Iba</th><th>Quantidade</th></tr></thead><tbody><tr><th class="table-secondary">0</th><td>1.00</td><td>1.00</td><td>0.78</td><td>1.00</td><td>0.88</td><td>0.79</td><td>56864</td></tr><tr><th class="table-secondary">1</th><td>0.97</td><td>0.78</td><td>1.00</td><td>0.86</td><td>0.88</td><td>0.76</td><td>98</td></tr><tr><th class="table-secondary">Total/Média</th><td>1.00</td><td>1.00</td><td>0.78</td><td>1.00</td><td>0.88</td><td>0.79</td><td>56962</td></tr></tbody></table></div><p class="mb-4"> Decidimos nos aprofundar no Random Forest e analisar os casos que ele classificou errado. Com as nossas análises, chegamos a conclusão que transações mal classificadas tinham valores de atributos parecidos com transações da classe oposta. Ou seja, fraudes mal classificadas tem atributos parecidos com não fraudes e não fraudes mal classificadas tem atributos parecidos com fraudes. Isso pode ser visualizado no gráfico: </p>',14),d={class:"chart-container mt-3 mb-3"},r=(0,s._)("p",{class:"mb-4"}," Além disso, a importãncia dos atributos clareia mais ainda a situação. Ele mostra que os atributos mais relevantes para o modelo fazer sua classificação são os mesmos que seguem a regra anteriormente vista. Isso tudo nos leva a crer que o modelo errou pois tais transações não possuem atributos comuns à sua classificação. Ou seja, em tais casos, fraudes se parecem com não fraudes e não fraudes se parecem com fraudes. ",-1),l={class:"chart-container mt-3 mb-3"},n=(0,s.uE)('<p class="mb-4"> Ademais, a fim de obtermos melhores resultados e uma análise mais profunda, decidimos retreinar o RandomForest selecionando atributos. Utlizamos a mesma ideia das quatro partições vista anteriormente. </p><p class="mb-4">Fizemos 3 tipos de seleção:</p><ul><li>Uma utilizando o TruncatedSVD</li><li>Uma utilizando o PCA</li><li>E uma excluindo os atributos</li></ul><p class="mb-4"> Nos dois primeiros casos, os algoritmos utilizados reduziram os atributos com menos de 2% de importância para quatro atributos, resultando numa base de dados com quinze atributos. Já no último caso, tais colunas foram descartadas, resultando numa base de dados com onze atributos. </p><p class="mb-4"> A redução de atributos obteve resultados muito semelhantes com os anteriores. Aqui vemos a matrix de confusão e as métricas obtidas com a exclusão de atributos e a utilização do Oversampling (RandomOverSampler) para o dataset de teste: </p><div class="tablePar"><table class="table tableMat table-bordered mb-4 mb-3"><caption> Predição do modelo </caption><thead class="table-success"><tr><th></th><th>0</th><th>1</th></tr></thead><tbody><tr><th class="table-secondary">0</th><td>56861</td><td>3</td></tr><tr><th class="table-secondary">1</th><td>23</td><td>75</td></tr></tbody></table></div><div class="chart-container mt-3 mb-3"><div class="tablePar"><table class="table table-bordered mb-4 mb-3"><caption> Métricas de avaliação do modelo </caption><thead class="table-success"><tr><th></th><th>Precision</th><th>Recall</th><th>F1</th><th>Specificity</th><th>Geom. Mean</th><th>Iba</th><th>Quantidade</th></tr></thead><tbody><tr><th class="table-secondary">0</th><td>1.00</td><td>1.00</td><td>0.77</td><td>1.00</td><td>0.87</td><td>0.78</td><td>56864</td></tr><tr><th class="table-secondary">1</th><td>0.96</td><td>0.77</td><td>1.00</td><td>0.85</td><td>0.87</td><td>0.75</td><td>98</td></tr><tr><th class="table-secondary">Total/Média</th><td>1.00</td><td>1.00</td><td>0.77</td><td>1.00</td><td>0.87</td><td>0.78</td><td>56962</td></tr></tbody></table></div></div><p class="mb-4">A importância dos atributos do mesmo modelo:</p>',8),c={class:"chart-container mt-3 mb-3"},m=(0,s.uE)('<p class="mb-4"> Portanto, concluímos que a redução de atributos não afeta significativamente a performance do modelo, mantendo resultados similares aos obtidos anteriormente. </p><p class="mb-4"> Em relação a seleção de atributos, concluímos que ela é benéfica, já que não prejudica a qualidade do modelo e aumenta a sua eficiência. Isso porque com menos atributos o modelo demora menos para ser treinado e sua complexidade diminui. </p><p class="mb-4"> Para melhorar as métricas obtidas, uma alternativa seria aumentar o número de atributos da base de dados. Isso porque, o modelo teria acesso à mais informação e poderia aprender melhor as características das transações fraudulentas e não fraudulentas. Dessa forma, reunimos sugestões de atributos que enriqueceriam esse dataset: </p><ul><li class="mb-2">Se é a primeira vez utilizando o cartão</li><li class="mb-2">Quantidade de transações recentes</li><li class="mb-2">Localização da transação</li><li class="mb-2"> Se feita por meio de aplicativo, quantidade de transações pelo mesmo dispositivo </li><li class="mb-2">Se conta está sendo acessada por dispositivo novo</li><li class="mb-2">Média de valor das transações da conta</li><li class="mb-2"> Se transação é maior do que o normal para aquela conta </li><li class="mb-2">Tipo de transação (Internet, PIX, Máquina, etc)</li><li class="mb-2">País da compra</li><li class="mb-2">Data da transação</li><li class="mb-4">Limite do cartão</li></ul><p class="mb-4"> Para ver a análise completa acesse: <a class="text-reset link-success link-underline-opacity-25 link-underline-opacity-100-hover" href="https://colab.research.google.com/drive/1G5NoHiNiGNh2n7u1FRblSz8YKFTTSqYm?usp=sharing" target="_blank">EntregaFinal.ipynb</a></p>',5);function v(a,e,t,v,u,p){const b=(0,s.up)("LineGraphParMedian"),h=(0,s.up)("BarGraphImpor"),f=(0,s.up)("BarGraphImporSel");return(0,s.wg)(),(0,s.iD)("div",o,[i,(0,s._)("div",d,[(0,s.Wm)(b)]),r,(0,s._)("div",l,[(0,s.Wm)(h)]),n,(0,s._)("div",c,[(0,s.Wm)(f)]),m])}var u=t(3354);function p(a,e,t,o,i,d){const r=(0,s.up)("Bar");return(0,s.wg)(),(0,s.j4)(r,{data:i.chartData,options:i.chartOptions},null,8,["data","options"])}var b=t(9646),h=t(5866);b.kL.register(b.uw,b.f$,b.ZL,b.Dx,b.u,b.De);var f={name:"BarGraphImpor",components:{Bar:h.$Q},data(){return{chartData:{labels:["v14","v10","v4","v12","v11","v17","v3","v16","v7","v2"],datasets:[{label:"Importância Atributos",backgroundColor:"#00ae31a8",data:[.288352,.1747,.142909,.131275,.080431,.068549,.044386,.027654,.026582,.015164]}]},chartOptions:{responsive:!0,scales:{},plugins:{legend:{position:"top",labels:{font:{size:19,family:"'Raleway', sans-serif"}}},title:{display:!0,text:"Correlação atributos",font:{size:19,family:"'Raleway', sans-serif"}},tooltip:{titleFont:{size:19,family:"'Raleway', sans-serif"},bodyFont:{size:19,family:" sans-serif"},padding:15}}}}}},g=t(89);const y=(0,g.Z)(f,[["render",p]]);var q=y;function z(a,e,t,o,i,d){const r=(0,s.up)("Line");return(0,s.wg)(),(0,s.j4)(r,{data:i.chartData,options:i.chartOptions},null,8,["data","options"])}t(7658);var P=JSON.parse('{"0":{"v1":0.8105622799,"v2":0.7382124035,"v3":0.6328494628,"v4":0.5416797291,"v5":0.4092721174,"v6":0.50970871,"v7":0.5926912685,"v8":0.7388194772,"v9":0.3748080917,"v10":0.4012694068,"v11":0.5493880139,"v12":0.5376179543,"v13":0.4672256274,"v14":0.4583918226,"v15":0.510344337,"v16":0.4639148623,"v17":0.5006326965,"v18":0.4967499524,"v19":0.5719031493,"v20":0.5311869226,"v21":0.4728719424,"v22":0.5177405868,"v23":0.5960816827,"v24":0.4034476301,"v25":0.5895307495,"v26":0.3624685055,"v27":0.7292841271,"v28":0.4327493668,"amount":0.001518,"label":1,"match":1,"line":0},"1":{"v1":0.9166617241,"v2":0.7044103979,"v3":0.7645446288,"v4":0.4205979208,"v5":0.4562276677,"v6":0.5448953723,"v7":0.6667781263,"v8":0.72170961,"v9":0.4401211102,"v10":0.4842565366,"v11":0.3500125743,"v12":0.761334997,"v13":0.4091607271,"v14":0.6476984887,"v15":0.499451139,"v16":0.7166976701,"v17":0.7497463605,"v18":0.7264763725,"v19":0.5385166739,"v20":0.5239349808,"v21":0.4565488627,"v22":0.5120060341,"v23":0.5996138678,"v24":0.4146842302,"v25":0.6099188391,"v26":0.3873677689,"v27":0.7108459657,"v28":0.4254585292,"amount":0.0011725,"label":1,"match":0,"line":1},"2":{"v1":0.9339170087,"v2":0.6921521262,"v3":0.7864180356,"v4":0.3034914738,"v5":0.4482793894,"v6":0.5513117244,"v7":0.6599986722,"v8":0.7248709041,"v9":0.4609413281,"v10":0.5050179156,"v11":0.2848294727,"v12":0.7980088014,"v13":0.4930717016,"v14":0.7100855601,"v15":0.5227194752,"v16":0.7181386585,"v17":0.7452714583,"v18":0.6941697669,"v19":0.5021851766,"v20":0.5201416465,"v21":0.4563642794,"v22":0.5159092697,"v23":0.5975987412,"v24":0.4206633454,"v25":0.5904337427,"v26":0.3644387578,"v27":0.7103970776,"v28":0.4238819619,"amount":0.0022,"label":0,"match":1,"line":2},"3":{"v1":0.8884047258,"v2":0.7214005333,"v3":0.6863893484,"v4":0.4021650569,"v5":0.3973337005,"v6":0.5079520055,"v7":0.5961081898,"v8":0.744849545,"v9":0.3714664815,"v10":0.3898396963,"v11":0.5208842674,"v12":0.4929670646,"v13":0.3576040092,"v14":0.4151348865,"v15":0.5063088731,"v16":0.4778205721,"v17":0.4537898666,"v18":0.4488434208,"v19":0.5997353835,"v20":0.5435115886,"v21":0.4783500551,"v22":0.5397417566,"v23":0.6006834512,"v24":0.4044863799,"v25":0.5956765229,"v26":0.3361081593,"v27":0.7434462157,"v28":0.4374802167,"amount":0.010499,"label":0,"match":0,"line":3}}');b.kL.register(b.uw,b.f$,b.od,b.jn,b.Dx,b.u,b.De);var S={name:"LineGraphParMedian",components:{Line:h.x1},data(){const a=[];let e,t="",s="#BBB";for(let o=0;o<4;o++)1==P[o]["line"]?(t="Fraude bem classificada",s="#ff3737d4",e="#ff3737d4"):2==P[o]["line"]?(t="Fraude mal classificada",s="#00ae31a8",e="#00ae31a8"):3==P[o]["line"]?(t="Não fraude bem classificada",s="#aa2afab4",e="#aa2afab4"):(t="Não fraude mal classificada",s="#1ba7e3b8",e="#1ba7e3b8"),a.push({label:t,backgroundColor:s,borderColor:e,data:[P[o]["v1"],P[o]["v2"],P[o]["v3"],P[o]["v4"],P[o]["v5"],P[o]["v6"],P[o]["v7"],P[o]["v8"],P[o]["v9"],P[o]["v10"],P[o]["v11"],P[o]["v12"],P[o]["v13"],P[o]["v14"],P[o]["v15"],P[o]["v16"],P[o]["v17"],P[o]["v18"],P[o]["v19"],P[o]["v20"],P[o]["v21"],P[o]["v22"],P[o]["v23"],P[o]["v24"],P[o]["v25"],P[o]["v26"],P[o]["v27"],P[o]["v28"],P[o]["amount"]]});return{data:P,chartData:{labels:["v1","v2","v3","v4","v5","v6","v7","v8","v9","v10","v11","v12","v13","v14","v15","v16","v17","v18","v19","v20","v21","v22","v23","v24","v25","v26","v27","v28","amount"],datasets:a},chartOptions:{responsive:!0,plugins:{legend:{position:"top",labels:{font:{size:19,family:"'Raleway', sans-serif"}}},title:{display:!0,text:"Valores dos atributos",font:{size:19,family:"'Raleway', sans-serif"}},tooltip:{titleFont:{size:19,family:"'Raleway', sans-serif"},bodyFont:{size:19,family:" sans-serif"},padding:15}}}}}};const M=(0,g.Z)(S,[["render",z]]);var F=M,R={components:{BarGraphImpor:u.Z,BarGraphImporSel:q,LineGraphParMedian:F}};const k=(0,g.Z)(R,[["render",v]]);var O=k}}]);
//# sourceMappingURL=465.cbd06135.js.map